{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speedy Compression Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.legend import Legend\n",
    "\n",
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "\n",
    "import hls4ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed and import tensorflow\n",
    "\n",
    "seed = 0\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from callbacks import all_callbacks\n",
    "\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset: fetch the jet tagging dataset and preprocess\n",
    "\n",
    "We are going to classify jets to five different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the dataset\n",
    "data = fetch_openml('hls4ml_lhc_jets_hlf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the inputs X and targets y\n",
    "X, y = data['data'], data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot encode the targets, e.g. \"w\" -> [0,0,1,0,0]\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "y = to_categorical(y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset: train and validation\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataset\n",
    "scaler = StandardScaler()\n",
    "X_train_val = scaler.fit_transform(X_train_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data as numpy arrays so you can just load it in case you need to restart\n",
    "np.save('X_train_val.npy', X_train_val)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('y_train_val.npy', y_train_val)\n",
    "np.save('y_test.npy', y_test)\n",
    "np.save('classes.npy', le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have to restart the notebook use these lines insead of fetching the dataset:\n",
    "\n",
    "# X_train_val = np.load('X_train_val.npy')\n",
    "# X_test = np.load('X_test.npy')\n",
    "# y_train_val = np.load('y_train_val.npy')\n",
    "# y_test = np.load('y_test.npy')\n",
    "# classes = np.load('classes.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The basline model: define the graph and train the baseline\n",
    "We'll use 3 hidden layers with 64, then 32, then 32 neurons. Each layer will use `relu` activation.\n",
    "Add an output layer with 5 neurons (one for each class), then finish with Softmax activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = Sequential()\n",
    "model_base.add(Dense(64, input_shape=(16,), name='fc1', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model_base.add(Activation(activation='relu', name='relu1'))\n",
    "model_base.add(Dense(32, name='fc2', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model_base.add(Activation(activation='relu', name='relu2'))\n",
    "model_base.add(Dense(32, name='fc3', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model_base.add(Activation(activation='relu', name='relu3'))\n",
    "model_base.add(Dense(5, name='output', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model_base.add(Activation(activation='softmax', name='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model: we'll use Adam optimizer with categorical crossentropy loss. The callbacks will decay the learning rate and save the model into a directory `model_base`. The model isn't very complex, so this should just take a few minutes even on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, name, y):\n",
    "    # Optimizer:\n",
    "    adam = Adam(learning_rate=0.0001)\n",
    "\n",
    "    # Compile the model, use crossentropy as a loss\n",
    "    model.compile(\n",
    "        optimizer=adam,\n",
    "        loss=['categorical_crossentropy'],\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    # Define callbacks\n",
    "    callbacks = all_callbacks(\n",
    "        stop_patience=1000,\n",
    "        lr_factor=0.5,\n",
    "        lr_patience=10,\n",
    "        lr_epsilon=0.000001,\n",
    "        lr_cooldown=2,\n",
    "        lr_minimum=0.0000001,\n",
    "        outputDir=name,\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(\n",
    "        X_train_val,\n",
    "        y,\n",
    "        batch_size=1024,\n",
    "        epochs=30,\n",
    "        validation_split=0.25,\n",
    "        shuffle=True,\n",
    "        callbacks=callbacks.callbacks,\n",
    "        verbose=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model_base, name=\"model_base\", y=y_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the performance of the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model1, name1, model2=None, name2=None):\n",
    "    y_keras = model1.predict(X_test, verbose=0)\n",
    "    print(f\"Accuracy {name1}: {accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_keras, axis=1))}\")\n",
    "    \n",
    "    if model2:\n",
    "        try:\n",
    "            y_keras2 = model2.predict(X_test, verbose=0)\n",
    "        except:\n",
    "            y_keras2 = model2.predict(np.ascontiguousarray(X_test))\n",
    "        print(f\"Accuracy {name2}: {accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_keras2, axis=1))}\")       \n",
    "\n",
    "    # Plot the ROC Curve\n",
    "    fig, ax = plt.subplots(figsize=(9, 9))\n",
    "    _ = plotting.makeRoc(y_test, y_keras, le.classes_)\n",
    "    \n",
    "    if model2:\n",
    "        plt.gca().set_prop_cycle(None)  # reset the colors\n",
    "        _ = plotting.makeRoc(y_test, y_keras2, le.classes_, linestyle='--')\n",
    "\n",
    "        lines = [Line2D([0], [0], ls='-'), Line2D([0], [0], ls='--')]\n",
    "        leg = Legend(ax, lines, labels=[name1, name2], loc='lower right', frameon=False)\n",
    "        ax.add_artist(leg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(model_base, \"Keras fp64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Distillation: train a smaller model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to experiment with knowledge distillation. We will train a smaller directly and using the labels generated by the baseline (a **student**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare soft labels\n",
    "\n",
    "y_teacher = model_base.predict(X_train_val, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a smaller model\n",
    "\n",
    "model_smaller = Sequential()\n",
    "model_smaller.add(Dense(16, input_shape=(16,), name='fc1', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model_smaller.add(Activation(activation='relu', name='relu1'))\n",
    "model_smaller.add(Dense(8, name='fc2', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model_smaller.add(Activation(activation='relu', name='relu2'))\n",
    "model_smaller.add(Dense(5, name='output', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model_smaller.add(Activation(activation='softmax', name='softmax'))\n",
    "\n",
    "train_model(model_smaller, name=\"model_smaller\", y=y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the student model (same architecture as the smaller model)\n",
    "\n",
    "model_student = Sequential()\n",
    "model_student.add(Dense(16, input_shape=(16,), name='fc1', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model_student.add(Activation(activation='relu', name='relu1'))\n",
    "model_student.add(Dense(8, name='fc2', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model_student.add(Activation(activation='relu', name='relu2'))\n",
    "model_student.add(Dense(5, name='output', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model_student.add(Activation(activation='softmax', name='softmax'))\n",
    "\n",
    "# NOTICE: the only difference with the above is the target label (y)\n",
    "train_model(model_student, name=\"model_student\", y=y_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the two approaches\n",
    "\n",
    "evaluation(model_smaller, \"Without KD\", model_student, \"With KD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/google/qkeras\n",
    "\n",
    "This time we're going to use QKeras layers. QKeras is \"Quantized Keras\" for deep heterogeneous quantization of ML models. It is maintained by Google and we recently added support for QKeras model to hls4ml.\n",
    "\n",
    "We're using `QDense` layer instead of `Dense`, and `QActivation` instead of `Activation`. We're also specifying `kernel_quantizer = quantized_bits(6,0,0)`. This will use 6-bits (of which 0 are integer) for the weights. We also use the same quantization for the biases, and `quantized_relu(6)` for 6-bit ReLU activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodel = Sequential()\n",
    "qmodel.add(\n",
    "    QDense(\n",
    "        16,\n",
    "        input_shape=(16,),\n",
    "        name='fc1',\n",
    "        kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "        bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "        kernel_initializer='lecun_uniform',\n",
    "        kernel_regularizer=l1(0.0001),\n",
    "    )\n",
    ")\n",
    "qmodel.add(QActivation(activation=quantized_relu(6), name='relu1'))\n",
    "qmodel.add(\n",
    "    QDense(\n",
    "        8,\n",
    "        name='fc2',\n",
    "        kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "        bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "        kernel_initializer='lecun_uniform',\n",
    "        kernel_regularizer=l1(0.0001),\n",
    "    )\n",
    ")\n",
    "qmodel.add(QActivation(activation=quantized_relu(6), name='relu2'))\n",
    "qmodel.add(\n",
    "    QDense(\n",
    "        5,\n",
    "        name='output',\n",
    "        kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "        bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "        kernel_initializer='lecun_uniform',\n",
    "        kernel_regularizer=l1(0.0001),\n",
    "    )\n",
    ")\n",
    "qmodel.add(Activation(activation='softmax', name='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(qmodel, name=\"qmodel\", y=y_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(model_student, \"fp64 with KD\", qmodel , \"qmodel with KD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the model to FPGA firmware with hls4ml\n",
    "\n",
    "Now we will go through the steps to convert the model we trained to a low-latency optimized FPGA firmware with hls4ml. First, we will evaluate its classification performance to make sure we haven't lost accuracy using the fixed-point data types.The hls4ml Neural Network inference library is controlled through a configuration dictionary. In this example we'll use the most simple variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = hls4ml.utils.config_from_keras_model(qmodel, granularity='name')\n",
    "\n",
    "# Necessary fo softmax layer\n",
    "config['LayerName']['softmax']['exp_table_t'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['softmax']['inv_table_t'] = 'ap_fixed<18,4>'\n",
    "\n",
    "print(\"-----------------------------------\")\n",
    "plotting.print_dict(config)\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    qmodel,\n",
    "    hls_config=config,\n",
    "    output_dir='model_cpp/project',\n",
    "    part='xcu250-figd2104-2L-e' # You can specify different part if necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualise what we created. The model architecture is shown, annotated with the shape and data types. Note that the default precision is `ap_fixed<16, 6>`, e.g. look at the `output` types. However the types for weight, bias and relu output are inherited from QKeras.\n",
    "\n",
    "*Advanced config*. You could change a type of the output in the config, for instance\n",
    "```config['LayerName']['fc1']['result'] = 'ap_fixed<10,2>'```\n",
    "It is a necessary step to assure accuracy or limit resource usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the graph\n",
    "\n",
    "hls4ml.utils.plot_model(hls_model, show_shapes=True, show_precision=True, to_file=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion was easy! Now let's see how the performance compares to Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(qmodel, \"QKeras\",  hls_model, \"hls4ml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look what files are generated. Please take time to take a look at these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls model_cpp/project/firmware/{*.h,*.cpp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthesize\n",
    "\n",
    "Finally, you can actually use Vivado HLS to synthesize the model. We can run the build using hls4ml API that simply calls `vivado_hls` or go to the terminal and run the synthesis directly. **`vivado_hls` needs to on PATH**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.build(csim=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
